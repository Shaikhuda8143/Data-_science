{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a03861",
   "metadata": {},
   "source": [
    "## WHY?\n",
    "* Convolutional Neural Network or CNN is a type of artificial neural network, which is widely **used for image/object recognition\n",
    "and classification.** Deep Learning thus recognizes objects in an image by using a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908172b6",
   "metadata": {},
   "source": [
    "# 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b32808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bb6e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f6810ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Conv2D,Dense,Dropout,MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870f429",
   "metadata": {},
   "source": [
    "### Uses\n",
    "* Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "* 'Conv2D' This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs\n",
    "* Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63cce9",
   "metadata": {},
   "source": [
    "# 2. Import Data using Augmentation Technique\n",
    "* Data augmentation in data analysis are techniques used to **increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data.**\n",
    "\n",
    "* It acts as a regularizer and **helps reduce overfitting when training a machine learning model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17237e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c46b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data   =ImageDataGenerator( shear_range=0.02,zoom_range=0.10,horizontal_flip=True,vertical_flip= True,rescale=1./255)\n",
    "validation_data =ImageDataGenerator(rescale=1./255)\n",
    "test_data       = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c844677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 3 classes.\n",
      "Found 6 images belonging to 3 classes.\n",
      "Found 5 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data_path   =training_data.flow_from_directory(directory=r'C:\\CNN_multiclass_classifier\\Train',\n",
    "                                     target_size=(128, 128))\n",
    "validation_data_path =validation_data.flow_from_directory(directory=r'C:\\CNN_multiclass_classifier\\Validation',\n",
    "                                     target_size=(128, 128))\n",
    "test_data_path       =test_data.flow_from_directory( directory=r'C:\\CNN_multiclass_classifier\\Test',\n",
    "                                     target_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14802636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Huda': 0, 'Mahi': 1, 'Zoya': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_path.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bba3c",
   "metadata": {},
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e6b96",
   "metadata": {},
   "source": [
    "### 3.1 Build the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "972dd4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 64, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 32, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               819300    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 830,511\n",
      "Trainable params: 830,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(input_shape=(128, 128, 3), filters=8,kernel_size=(3,3), strides=1, padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2, padding='same'))\n",
    "model.add(Conv2D(filters=8,kernel_size=(3,3), strides=1, padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54f957",
   "metadata": {},
   "source": [
    "# 3.2 Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46c84c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9382daa",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52162023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1122 - accuracy: 0.3214 - val_loss: 1.1014 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 1.0968 - accuracy: 0.5714 - val_loss: 1.3924 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 1.3073 - accuracy: 0.3214 - val_loss: 1.0337 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.9812 - accuracy: 0.6429 - val_loss: 1.0519 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 1.0358 - accuracy: 0.4286 - val_loss: 1.0765 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.9776 - accuracy: 0.3929 - val_loss: 1.0499 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.9347 - accuracy: 0.5357 - val_loss: 1.0078 - val_accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.8740 - accuracy: 0.7500 - val_loss: 0.9843 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.8249 - accuracy: 0.7143 - val_loss: 0.9960 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.8043 - accuracy: 0.7500 - val_loss: 1.0357 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "training_model = model.fit(x=training_data_path,batch_size=32,epochs=10,validation_data=validation_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7031b27",
   "metadata": {},
   "source": [
    "# 5. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d37d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('image_recognitoion.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d2a2f",
   "metadata": {},
   "source": [
    "# 6. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f2db6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Huda': 0, 'Mahi': 1, 'Zoya': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_path.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a14b3d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huda\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img(r\"C:\\CNN_multiclass_classifier\\Test\\Huda\\IMG_20220206_185332.jpg\",target_size = (128,128))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "# load model\n",
    "model = load_model('image_recognitoion.h5')\n",
    "result = model.predict(test_image)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    print('Huda')\n",
    "   \n",
    "elif result[0][1] ==1:\n",
    "    print('Mahi')\n",
    "    \n",
    "else:\n",
    "    print('Zoyu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
